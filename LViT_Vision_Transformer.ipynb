{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/haseebkhan9081/LViT_Vision_Transformer/blob/main/LViT_Vision_Transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVL3DmL6GgiS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73ed3a94-5910-4727-9466-269c65ccc040"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UiEhAldfHcwG"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "import os\n",
        "#os.chdir('D:/Traffic_Sign_Recognition')\n",
        "from sklearn.model_selection import train_test_split\n",
        "#from keras.utils import to_categorical\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow==2.13.0\n"
      ],
      "metadata": {
        "id": "POneEaYhXqJU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c5eb9ce8-6fad-4dfb-d402-cac1ea4e7d23"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow==2.13.0\n",
            "  Downloading tensorflow-2.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.1.21 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (24.3.25)\n",
            "Collecting gast<=0.4.0,>=0.2.1 (from tensorflow==2.13.0)\n",
            "  Downloading gast-0.4.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (1.67.1)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (3.12.1)\n",
            "Collecting keras<2.14,>=2.13.1 (from tensorflow==2.13.0)\n",
            "  Downloading keras-2.13.1-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (18.1.1)\n",
            "Collecting numpy<=1.24.3,>=1.22 (from tensorflow==2.13.0)\n",
            "  Downloading numpy-1.24.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (4.25.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (1.16.0)\n",
            "Collecting tensorboard<2.14,>=2.13 (from tensorflow==2.13.0)\n",
            "  Downloading tensorboard-2.13.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting tensorflow-estimator<2.14,>=2.13.0 (from tensorflow==2.13.0)\n",
            "  Downloading tensorflow_estimator-2.13.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (2.5.0)\n",
            "Collecting typing-extensions<4.6.0,>=3.6.6 (from tensorflow==2.13.0)\n",
            "  Downloading typing_extensions-4.5.0-py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (1.16.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.13.0) (0.44.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2.27.0)\n",
            "Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard<2.14,>=2.13->tensorflow==2.13.0)\n",
            "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.7)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2.32.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.1.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.2.2)\n",
            "Downloading tensorflow-2.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (524.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m524.1/524.1 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Downloading keras-2.13.1-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m74.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.24.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m97.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m106.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_estimator-2.13.0-py2.py3-none-any.whl (440 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.8/440.8 kB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
            "Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
            "Installing collected packages: typing-extensions, tensorflow-estimator, numpy, keras, gast, google-auth-oauthlib, tensorboard, tensorflow\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.12.2\n",
            "    Uninstalling typing_extensions-4.12.2:\n",
            "      Successfully uninstalled typing_extensions-4.12.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 3.4.1\n",
            "    Uninstalling keras-3.4.1:\n",
            "      Successfully uninstalled keras-3.4.1\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.6.0\n",
            "    Uninstalling gast-0.6.0:\n",
            "      Successfully uninstalled gast-0.6.0\n",
            "  Attempting uninstall: google-auth-oauthlib\n",
            "    Found existing installation: google-auth-oauthlib 1.2.1\n",
            "    Uninstalling google-auth-oauthlib-1.2.1:\n",
            "      Successfully uninstalled google-auth-oauthlib-1.2.1\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.17.0\n",
            "    Uninstalling tensorboard-2.17.0:\n",
            "      Successfully uninstalled tensorboard-2.17.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.17.0\n",
            "    Uninstalling tensorflow-2.17.0:\n",
            "      Successfully uninstalled tensorflow-2.17.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "sqlalchemy 2.0.36 requires typing-extensions>=4.6.0, but you have typing-extensions 4.5.0 which is incompatible.\n",
            "albucore 0.0.19 requires numpy>=1.24.4, but you have numpy 1.24.3 which is incompatible.\n",
            "albumentations 1.4.20 requires numpy>=1.24.4, but you have numpy 1.24.3 which is incompatible.\n",
            "langchain-core 0.3.15 requires typing-extensions>=4.7, but you have typing-extensions 4.5.0 which is incompatible.\n",
            "nibabel 5.3.2 requires typing-extensions>=4.6; python_version < \"3.13\", but you have typing-extensions 4.5.0 which is incompatible.\n",
            "openai 1.54.3 requires typing-extensions<5,>=4.11, but you have typing-extensions 4.5.0 which is incompatible.\n",
            "pydantic 2.9.2 requires typing-extensions>=4.6.1; python_version < \"3.13\", but you have typing-extensions 4.5.0 which is incompatible.\n",
            "pydantic-core 2.23.4 requires typing-extensions!=4.7.0,>=4.6.0, but you have typing-extensions 4.5.0 which is incompatible.\n",
            "tf-keras 2.17.0 requires tensorflow<2.18,>=2.17, but you have tensorflow 2.13.0 which is incompatible.\n",
            "torch 2.5.0+cu121 requires typing-extensions>=4.8.0, but you have typing-extensions 4.5.0 which is incompatible.\n",
            "typeguard 4.4.1 requires typing-extensions>=4.10.0, but you have typing-extensions 4.5.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gast-0.4.0 google-auth-oauthlib-1.0.0 keras-2.13.1 numpy-1.24.3 tensorboard-2.13.0 tensorflow-2.13.0 tensorflow-estimator-2.13.0 typing-extensions-4.5.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "gast",
                  "keras",
                  "numpy",
                  "tensorflow"
                ]
              },
              "id": "17599690e554490d851234e56dea1bf7"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow_addons\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUIjldqicRQA",
        "outputId": "18d495a2-10b7-49e5-9b89-c0e03fa15e51"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow_addons\n",
            "  Downloading tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow_addons) (24.2)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow_addons)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl.metadata (3.6 kB)\n",
            "Downloading tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (611 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.8/611.8 kB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: typeguard, tensorflow_addons\n",
            "  Attempting uninstall: typeguard\n",
            "    Found existing installation: typeguard 4.4.1\n",
            "    Uninstalling typeguard-4.4.1:\n",
            "      Successfully uninstalled typeguard-4.4.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "inflect 7.4.0 requires typeguard>=4.0.1, but you have typeguard 2.13.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed tensorflow_addons-0.23.0 typeguard-2.13.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from PIL import Image\n",
        "import tensorflow_addons as tfa"
      ],
      "metadata": {
        "id": "B0Qh6cdRXmBV"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgWuaf01I0po"
      },
      "source": [
        "data = []\n",
        "labels = []\n",
        "# We have 43 Classes\n",
        "# classes = ['Bengincases', 'Malignantcases', 'Normalcases']\n",
        "classes = 3\n",
        "cur_path = '/content/drive/MyDrive/Sem7/ResearchPaper'\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbpyFEAUI4nX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "e0c86993-3f70-4d07-e386-d734952b7fba"
      },
      "source": [
        "cur_path"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/Sem7/ResearchPaper'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 0 benign cancer images\n",
        "# 1 malignant cancer images\n",
        "# 2 normal images\n",
        "\n",
        "for i in range(classes):\n",
        "    path = os.path.join(cur_path,'train',str(i))\n",
        "    print(path)\n",
        "    images = os.listdir(path)\n",
        "    for a in images:\n",
        "        try:\n",
        "            image = Image.open(path + '/'+ a)\n",
        "            image = image.resize((30,30))\n",
        "            image = np.array(image)\n",
        "            data.append(image)\n",
        "            labels.append(i)\n",
        "        except Exception as e:\n",
        "            print(e)"
      ],
      "metadata": {
        "id": "7JY2tnE4NlIm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccd56fae-8330-44c4-c7de-1e3ea01d23e1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Sem7/ResearchPaper/train/0\n",
            "/content/drive/MyDrive/Sem7/ResearchPaper/train/1\n",
            "/content/drive/MyDrive/Sem7/ResearchPaper/train/2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = np.array(data)\n",
        "labels = np.array(labels)"
      ],
      "metadata": {
        "id": "m9RGRhkcUd3-"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data.shape, labels.shape)"
      ],
      "metadata": {
        "id": "8i36hLTwUm-M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bf81952-9982-48c9-a9e1-8fb248d64f5c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1097, 30, 30, 3) (1097,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=0)"
      ],
      "metadata": {
        "id": "7jGo1JvcUxKL"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
      ],
      "metadata": {
        "id": "uH-jfXdNUzRy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e811721-cb98-444f-b4ff-47cd08d06580"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(877, 30, 30, 3) (220, 30, 30, 3) (877,) (220,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(4, 4))\n",
        "image = X_train[np.random.choice(range(X_train.shape[0]))]\n",
        "plt.imshow(image.astype(\"uint8\"))\n",
        "plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "iyXONzUqY7IH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "outputId": "18b05c17-c29f-49ab-f7b6-18e479c8d19d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-0.5, 29.5, 29.5, -0.5)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 400x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#from keras.utils import to_categorical\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "etcT06UMVIzi"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_augmentation = keras.Sequential(\n",
        "    [\n",
        "        layers.Normalization(),\n",
        "        layers.Resizing(72, 72),\n",
        "        layers.RandomFlip(\"horizontal\"),\n",
        "        layers.RandomRotation(factor=0.02),\n",
        "        layers.RandomZoom(\n",
        "            height_factor=0.2, width_factor=0.2\n",
        "        ),\n",
        "    ],\n",
        "    name=\"data_augmentation\",\n",
        ")\n",
        "# Compute the mean and the variance of the training data for normalization.\n",
        "data_augmentation.layers[0].adapt(X_train)"
      ],
      "metadata": {
        "id": "ehmrc5ctVd2X"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mlp(x, hidden_units, dropout_rate):\n",
        "    for units in hidden_units:\n",
        "        x = layers.Dense(units, activation=tf.nn.gelu)(x)\n",
        "        x = layers.Dropout(dropout_rate)(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "HqY2ydJ7WCvU"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.001\n",
        "weight_decay = 0.0001\n",
        "batch_size = 256\n",
        "num_epochs = 120\n",
        "image_size = 72  # We'll resize input images to this size\n",
        "patch_size = 6  # Size of the patches to be extract from the input images\n",
        "num_patches = (image_size // patch_size) ** 2\n",
        "projection_dim = 64\n",
        "num_heads = 8       #6,7,8,9,10,11,12\n",
        "transformer_units = [\n",
        "    projection_dim * 2,\n",
        "    projection_dim,\n",
        "]  # Size of the transformer layers\n",
        "transformer_layers = 8\n",
        "mlp_head_units = [2048, 1024]  # Size of the dense layers of the final classifier"
      ],
      "metadata": {
        "id": "UJ_GEltFNI3Y"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Patches(layers.Layer):\n",
        "    def __init__(self, patch_size):\n",
        "        super(Patches, self).__init__()\n",
        "        self.patch_size = patch_size\n",
        "\n",
        "    def call(self, images):\n",
        "        batch_size = tf.shape(images)[0]\n",
        "        patches = tf.image.extract_patches(\n",
        "            images=images,\n",
        "            sizes=[1, self.patch_size, self.patch_size, 1],\n",
        "            strides=[1, self.patch_size, self.patch_size, 1],\n",
        "            rates=[1, 1, 1, 1],\n",
        "            padding=\"VALID\",\n",
        "        )\n",
        "        patch_dims = patches.shape[-1]\n",
        "        patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n",
        "        return patches"
      ],
      "metadata": {
        "id": "_u0m-JVQNL7W"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resized_image = tf.image.resize(\n",
        "    tf.convert_to_tensor([image]), size=(image_size, image_size)\n",
        ")\n",
        "patches = Patches(patch_size)(resized_image)\n",
        "print(f\"Image size: {image_size} X {image_size}\")\n",
        "print(f\"Patch size: {patch_size} X {patch_size}\")\n",
        "print(f\"Patches per image: {patches.shape[1]}\")\n",
        "print(f\"Elements per patch: {patches.shape[-1]}\")\n",
        "\n",
        "n = int(np.sqrt(patches.shape[1]))\n",
        "plt.figure(figsize=(4, 4))\n",
        "for i, patch in enumerate(patches[0]):\n",
        "    ax = plt.subplot(n, n, i + 1)\n",
        "    patch_img = tf.reshape(patch, (patch_size, patch_size, 3))\n",
        "    plt.imshow(patch_img.numpy().astype(\"uint8\"))\n",
        "    plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "CVvwk1u0NghH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "outputId": "5c357276-166e-426d-b8ef-5e6dc627a31c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image size: 72 X 72\n",
            "Patch size: 6 X 6\n",
            "Patches per image: 144\n",
            "Elements per patch: 108\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 400x400 with 144 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class PatchEncoder(layers.Layer):\n",
        "    def __init__(self, num_patches, projection_dim):\n",
        "        super(PatchEncoder, self).__init__()\n",
        "        self.num_patches = num_patches\n",
        "        self.projection = layers.Dense(units=projection_dim)\n",
        "        self.position_embedding = layers.Embedding(\n",
        "            input_dim=num_patches, output_dim=projection_dim\n",
        "        )\n",
        "\n",
        "    def call(self, patch):\n",
        "        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n",
        "        encoded = self.projection(patch) + self.position_embedding(positions)\n",
        "        return encoded"
      ],
      "metadata": {
        "id": "kj43Cy_9Ns7a"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (30, 30, 3)"
      ],
      "metadata": {
        "id": "7RIrNFGFPcEN"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_vit_classifier():\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "    # Augment data.\n",
        "    augmented = data_augmentation(inputs)\n",
        "    # Create patches.\n",
        "    patches = Patches(patch_size)(augmented)\n",
        "    # Encode patches.\n",
        "    encoded_patches = PatchEncoder(num_patches, projection_dim)(patches)\n",
        "\n",
        "    # Create multiple layers of the Transformer block.\n",
        "    for _ in range(transformer_layers):\n",
        "        # Layer normalization 1.\n",
        "        x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
        "        # Create a multi-head attention layer.\n",
        "        attention_output = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=projection_dim, dropout=0.1\n",
        "        )(x1, x1)\n",
        "        # Skip connection 1.\n",
        "        x2 = layers.Add()([attention_output, encoded_patches])\n",
        "        # Layer normalization 2.\n",
        "        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
        "        # MLP.\n",
        "        x3 = mlp(x3, hidden_units=transformer_units, dropout_rate=0.1)\n",
        "        # Skip connection 2.\n",
        "        encoded_patches = layers.Add()([x3, x2])\n",
        "\n",
        "    # Create a [batch_size, projection_dim] tensor.\n",
        "    representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
        "    representation = layers.Flatten()(representation)\n",
        "    representation = layers.Dropout(0.5)(representation)\n",
        "    # Add MLP.\n",
        "    features = mlp(representation, hidden_units=mlp_head_units, dropout_rate=0.5)\n",
        "    # Classify outputs.\n",
        "    logits = layers.Dense(classes)(features)\n",
        "    # Create the Keras model.\n",
        "    model = keras.Model(inputs=inputs, outputs=logits)\n",
        "    return model\n",
        "\n",
        "# vit_classifier = create_vit_classifier()\n"
      ],
      "metadata": {
        "id": "UMQNuDeeN0Sf"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_experiment(model):\n",
        "    optimizer = tfa.optimizers.AdamW(\n",
        "        learning_rate=learning_rate, weight_decay=weight_decay\n",
        "    )\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "        metrics=[\n",
        "            keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\"),\n",
        "            keras.metrics.SparseTopKCategoricalAccuracy(5, name=\"top-5-accuracy\"),\n",
        "        ],\n",
        "    )\n",
        "\n",
        "    checkpoint_filepath = \"/tmp/checkpoint\"\n",
        "    checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
        "        checkpoint_filepath,\n",
        "        monitor=\"val_accuracy\",\n",
        "        save_best_only=True,\n",
        "        save_weights_only=True,\n",
        "    )\n",
        "\n",
        "    history = model.fit(\n",
        "        x=X_train,\n",
        "        y=y_train,\n",
        "        batch_size=batch_size,\n",
        "        epochs=num_epochs,\n",
        "        validation_split=0.1,\n",
        "        callbacks=[checkpoint_callback],\n",
        "    )\n",
        "\n",
        "    model.load_weights(checkpoint_filepath)\n",
        "    _, accuracy, top_5_accuracy = model.evaluate(X_test, y_test)\n",
        "    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
        "    print(f\"Test top 5 accuracy: {round(top_5_accuracy * 100, 2)}%\")\n",
        "\n",
        "    return history\n",
        "\n",
        "\n",
        "vit_classifier = create_vit_classifier()\n",
        "history = run_experiment(vit_classifier)"
      ],
      "metadata": {
        "id": "Q8SsKll6N6Zu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6018c04-8670-4fe8-bdf6-19a2af216660"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/120\n",
            "4/4 [==============================] - 109s 21s/step - loss: 21.7829 - accuracy: 0.3333 - top-5-accuracy: 1.0000 - val_loss: 10.8169 - val_accuracy: 0.4432 - val_top-5-accuracy: 1.0000\n",
            "Epoch 2/120\n",
            "4/4 [==============================] - 97s 22s/step - loss: 6.6574 - accuracy: 0.4880 - top-5-accuracy: 1.0000 - val_loss: 1.3293 - val_accuracy: 0.4432 - val_top-5-accuracy: 1.0000\n",
            "Epoch 3/120\n",
            "4/4 [==============================] - 98s 22s/step - loss: 1.6207 - accuracy: 0.4918 - top-5-accuracy: 1.0000 - val_loss: 1.0656 - val_accuracy: 0.4432 - val_top-5-accuracy: 1.0000\n",
            "Epoch 4/120\n",
            "4/4 [==============================] - 94s 22s/step - loss: 1.2460 - accuracy: 0.4816 - top-5-accuracy: 1.0000 - val_loss: 0.8048 - val_accuracy: 0.7159 - val_top-5-accuracy: 1.0000\n",
            "Epoch 5/120\n",
            "4/4 [==============================] - 89s 20s/step - loss: 1.1838 - accuracy: 0.5501 - top-5-accuracy: 1.0000 - val_loss: 0.8492 - val_accuracy: 0.5455 - val_top-5-accuracy: 1.0000\n",
            "Epoch 6/120\n",
            "4/4 [==============================] - 88s 20s/step - loss: 1.0487 - accuracy: 0.5475 - top-5-accuracy: 1.0000 - val_loss: 0.8708 - val_accuracy: 0.6250 - val_top-5-accuracy: 1.0000\n",
            "Epoch 7/120\n",
            "4/4 [==============================] - 89s 20s/step - loss: 1.0448 - accuracy: 0.5450 - top-5-accuracy: 1.0000 - val_loss: 0.7895 - val_accuracy: 0.6591 - val_top-5-accuracy: 1.0000\n",
            "Epoch 8/120\n",
            "2/4 [==============>...............] - ETA: 57s - loss: 0.9767 - accuracy: 0.5586 - top-5-accuracy: 1.0000 "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#history.history ??\n",
        "history.history.keys()\n",
        "print(history.history['accuracy'])"
      ],
      "metadata": {
        "id": "QxC1FPV3LICd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "22543413-ef73-47b8-f556-3bcea4677e90"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'history' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-64a5167bc168>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#history.history ??\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history.history"
      ],
      "metadata": {
        "id": "FRIwihSFZ7_4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "loss_train = history.history['accuracy']\n",
        "loss_val = history.history['val_accuracy']\n",
        "epochs = range(0,num_epochs)\n",
        "plt.plot(epochs, loss_train, 'g', label='Training accuracy')\n",
        "#plt.plot(epochs, loss_val, 'b', label='validation accuracy')\n",
        "plt.title('Training and Validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "print('epochs: ',num_epochs,' heads: ',num_heads)"
      ],
      "metadata": {
        "id": "gC2bxNSOMAXT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=[8,6])\n",
        "plt.plot(history.history['loss'],'r',linewidth=3.0)\n",
        "plt.plot(history.history['val_loss'],'b',linewidth=3.0)\n",
        "plt.legend(['Training loss', 'Validation Loss'],fontsize=18)\n",
        "plt.xlabel('Epochs ',fontsize=16)\n",
        "plt.ylabel('Loss',fontsize=16)\n",
        "plt.title('Loss Curves',fontsize=16)\n",
        "\n",
        "# Accuracy Curves\n",
        "plt.figure(figsize=[8,6])\n",
        "plt.plot(history.history['accuracy'],'r',linewidth=3.0)\n",
        "plt.plot(history.history['val_accuracy'],'b',linewidth=3.0)\n",
        "plt.legend(['Training Accuracy', 'Validation Accuracy'],fontsize=18)\n",
        "plt.xlabel('Epochs ',fontsize=16)\n",
        "plt.ylabel('Accuracy',fontsize=16)\n",
        "plt.title('Accuracy Curves',fontsize=16)\n",
        "\n",
        "print('epochs: ',num_epochs,' heads: ',num_heads)"
      ],
      "metadata": {
        "id": "gde92amIMKbU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%ls"
      ],
      "metadata": {
        "id": "ztAaYL0zbml1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vit_classifier.save_weights('drive/MyDrive/Sem7/ResearchPaper/savedmodel/vit_classifier')\n"
      ],
      "metadata": {
        "id": "7ATVXsgdwVmH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vit_classifier.save('vit_model')"
      ],
      "metadata": {
        "id": "uQIE7O580G5B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XYeRh0upUng-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vit_model = create_vit_classifier()\n",
        "vit_model.load_weights('drive/MyDrive/Sem7/ResearchPaper/savedmodel/vit_classifier.h5')\n"
      ],
      "metadata": {
        "id": "eortBz3dlLKa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=0)\n",
        "print(y_test)\n",
        "x_outputs = vit_model.predict(data)\n"
      ],
      "metadata": {
        "id": "F9vuEqWCdqub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test"
      ],
      "metadata": {
        "id": "wpeMfIF92yVx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n"
      ],
      "metadata": {
        "id": "vArOmWOTZrPW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_values = []\n",
        "\n",
        "for i in x_outputs:\n",
        "    predicted_values.append(i.argmax(axis=0))\n",
        "\n"
      ],
      "metadata": {
        "id": "mV8w48MQ5t7s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_test.shape, x_outputs.shape)\n",
        "\n",
        "print(y_test)\n",
        "print(x_outputs)"
      ],
      "metadata": {
        "id": "ex0agqkJ3hkB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "# X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=0)\n",
        "\n",
        "# __label = ['benign', 'malignant', 'normal']\n",
        "\n",
        "cm = confusion_matrix(labels, predicted_values)\n",
        "\n",
        "print(cm)\n",
        "\n",
        "disp = ConfusionMatrixDisplay(cm,display_labels=['benign', 'malignant', 'normal'])\n",
        "disp.plot(xticks_rotation=45)"
      ],
      "metadata": {
        "id": "T8UP3h6NNuMq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(cm)"
      ],
      "metadata": {
        "id": "CpAVKU1pN31k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc_matrix = []\n",
        "for i in cm:\n",
        "    tmp = []\n",
        "    for j in i:\n",
        "        tmp.append(j/sum(i))\n",
        "    acc_matrix.append(tmp)"
      ],
      "metadata": {
        "id": "jbuhyWTQFGSy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.matrix(acc_matrix))"
      ],
      "metadata": {
        "id": "EC7n0rG1FPXw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# disp = ConfusionMatrixDisplay()\n",
        "disp = ConfusionMatrixDisplay(np.matrix(acc_matrix),display_labels=['benign', 'malignant', 'normal'])\n",
        "\n",
        "disp.plot(xticks_rotation=45)"
      ],
      "metadata": {
        "id": "8F0CqE_OF00H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gXJ_uDe9c9xU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}